'use client';

import { useState } from 'react';
import { Award, CheckCircle, XCircle, Lock, Trophy, Brain, Zap, Target, Home, BookOpen, ExternalLink, AlertCircle } from 'lucide-react';

const KIKompetenzTest = () => {
  const [view, setView] = useState('menu'); // 'menu', 'question', 'levelComplete', 'learn'
  const [currentLevel, setCurrentLevel] = useState(1);
  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [selectedAnswer, setSelectedAnswer] = useState(null);
  const [showExplanation, setShowExplanation] = useState(false);
  const [levelScores, setLevelScores] = useState({ 1: [], 2: [], 3: [] });
  const [completedLevels, setCompletedLevels] = useState([]);
  const [showHowItWorks, setShowHowItWorks] = useState(false);

  const questions = {
    1: [
      {
        question: "Ihr Team mÃ¶chte einen Chatbot fÃ¼r die BÃ¼rger-Hotline einsetzen. Nach EU AI Act: Was mÃ¼sst ihr mindestens tun?",
        options: [
          "Nichts Besonderes - Chatbots sind unkritisch",
          "Nutzer darÃ¼ber informieren, dass sie mit einer KI sprechen",
          "Eine vollstÃ¤ndige SicherheitsprÃ¼fung durchfÃ¼hren",
          "Das System ist verboten"
        ],
        correct: 1,
        explanation: "Chatbots fallen unter 'begrenztes Risiko' mit Transparenzpflicht. Nutzer mÃ¼ssen klar erkennen kÃ¶nnen, dass sie mit einer KI interagieren - nicht mit einem Menschen. Das schÃ¼tzt vor TÃ¤uschung und ermÃ¶glicht informierte Entscheidungen.",
        tip: "ðŸ’¡ Transparenz ist ein Grundprinzip: Menschen haben das Recht zu wissen, wann sie mit KI interagieren."
      },
      {
        question: "Eure Firma nutzt seit Jahren ein System, das Bewerbungen automatisch vorsortiert. Was ist ab August 2026 neu?",
        options: [
          "Solche Systeme sind jetzt komplett verboten",
          "Es gelten strenge Dokumentations- und PrÃ¼fpflichten",
          "Nur groÃŸe Konzerne mÃ¼ssen sich darum kÃ¼mmern",
          "Nichts - Bestandssysteme sind ausgenommen"
        ],
        correct: 1,
        explanation: "KI-Systeme im HR-Bereich gelten als 'Hochrisiko', weil sie Lebenschancen beeinflussen. Ab August 2026 braucht ihr: technische Dokumentation, Risikoanalyse, QualitÃ¤tsmanagement und regelmÃ¤ÃŸige Tests auf Fairness. Keine Ausnahme fÃ¼r Altsysteme!",
        tip: "âš–ï¸ HR-KI ist Hochrisiko: Jobs und Karrieren stehen auf dem Spiel."
      },
      {
        question: "Ein KI-System zur Mitarbeiter-Ãœberwachung soll messen, wie produktiv jeder ist. EU AI Act sagt dazu:",
        options: [
          "Erlaubt, wenn Betriebsrat zustimmt",
          "Erlaubt mit Transparenzpflicht",
          "Hochrisiko - strenge Auflagen nÃ¶tig",
          "Komplett verboten"
        ],
        correct: 2,
        explanation: "Ãœberwachung und Bewertung von Arbeitnehmern ist Hochrisiko-KI. Erlaubt unter strengen Bedingungen: Risikomanagement, Transparenz, menschliche Aufsicht, Grundrechte-PrÃ¼fung. Aber Achtung: Manipulation oder unterschwellige Beeinflussung wÃ¤re verboten!",
        tip: "ðŸ‘ï¸ Mitarbeiter haben besondere Schutzrechte - auch vor KI."
      },
      {
        question: "Welches dieser KI-Systeme ist ab Februar 2025 verboten?",
        options: [
          "Social Scoring - BÃ¼rger nach Verhalten bewerten",
          "Spam-Filter fÃ¼r E-Mails",
          "Navigationssysteme mit KI",
          "Ãœbersetzungs-Tools"
        ],
        correct: 0,
        explanation: "Social Scoring (wie in China) ist 'unannehmbares Risiko' und seit Februar 2025 verboten. Es verletzt Grundrechte und MenschenwÃ¼rde. Auch verboten: unterschwellige Manipulation, Ausnutzung von SchwÃ¤chen verletzlicher Gruppen.",
        tip: "ðŸš« Unannehmbares Risiko = absolutes Verbot. Keine Diskussion."
      },
      {
        question: "Ihr nutzt ChatGPT in der Verwaltung. Was muss ab sofort dokumentiert werden?",
        options: [
          "Gar nichts - ist ja nur ein Tool",
          "Nur wenn sensible Daten verarbeitet werden",
          "Welche Mitarbeiter geschult wurden",
          "Jede einzelne Anfrage"
        ],
        correct: 2,
        explanation: "Seit Februar 2025 gilt: Mitarbeiter mÃ¼ssen im Umgang mit genutzten KI-Systemen geschult sein - und das muss dokumentiert werden. Nicht jede Anfrage, aber wer wann geschult wurde. Das zeigt Sorgfaltspflicht und schÃ¼tzt bei Haftungsfragen.",
        tip: "ðŸ“š Schulung + Dokumentation = eure Absicherung bei Problemen."
      },
      {
        question: "Ein Startup bietet euch ein 'KI-Tool zur KreditwÃ¼rdigkeitsprÃ¼fung' an. Welche Frage ist am wichtigsten?",
        options: [
          "Ist das Tool DSGVO-konform?",
          "Wie wurde es auf Bias getestet?",
          "Was kostet die Lizenz?",
          "Gibt es eine kostenlose Testversion?"
        ],
        correct: 1,
        explanation: "KreditwÃ¼rdigkeit = Hochrisiko-KI! Bias kann Menschen systematisch benachteiligen (z.B. nach Geschlecht, Alter, Herkunft). Ihr mÃ¼sst wissen: Welche Daten? Wie getestet? Welche Fehlerrate bei verschiedenen Gruppen? Sonst drohen Diskriminierung UND Strafen bis 6% Jahresumsatz.",
        tip: "âš ï¸ Bei Hochrisiko-KI immer nach Bias-Tests fragen!"
      },
      {
        question: "Was bedeutet 'Hochrisiko-KI' konkret fÃ¼r euch als Betreiber?",
        options: [
          "Ihr dÃ¼rft sie nicht nutzen",
          "Ihr braucht eine spezielle Lizenz",
          "Ihr mÃ¼sst Risikomanagement betreiben und Tests durchfÃ¼hren",
          "Nur der Anbieter ist verantwortlich"
        ],
        correct: 2,
        explanation: "Als Betreiber von Hochrisiko-KI seid IHR verantwortlich fÃ¼r: Einhaltung der Vorgaben, angemessene menschliche Aufsicht, Ãœberwachung der Funktion, Meldung von schweren VorfÃ¤llen. Der Anbieter liefert das System, aber ihr setzt es ein - also tragt ihr Mitverantwortung!",
        tip: "ðŸ¤ Verantwortung wird geteilt: Anbieter UND Betreiber."
      },
      {
        question: "Ein BÃ¼rger fragt: 'Hat eine KI Ã¼ber meinen Antrag entschieden?' Eure Pflicht:",
        options: [
          "Muss nicht beantwortet werden",
          "Nur beantworten, wenn ein Anwalt fragt",
          "Klar und verstÃ¤ndlich erklÃ¤ren + Widerspruchsrecht nennen",
          "An den IT-Support verweisen"
        ],
        correct: 2,
        explanation: "Transparenzpflicht! Bei Hochrisiko-KI haben Betroffene das Recht auf klare Information: Wurde KI eingesetzt? Wie funktioniert sie? Wie kann ich widersprechen? Antwort muss verstÃ¤ndlich sein - keine Fachsprache. Das stÃ¤rkt Vertrauen und ist rechtlich vorgeschrieben.",
        tip: "ðŸ—£ï¸ VerstÃ¤ndliche Kommunikation schafft Vertrauen."
      }
    ],
    2: [
      {
        question: "Eure Bewerbungs-KI lehnt auffÃ¤llig oft Frauen Ã¼ber 40 ab. Welcher Bias-Typ liegt hier am wahrscheinlichsten vor?",
        options: [
          "Historical Bias - frÃ¼her wurden weniger Frauen eingestellt",
          "Algorithmic Bias - der Algorithmus ist fehlerhaft",
          "User Interaction Bias - falsche Nutzung",
          "Measurement Bias - falsche Metriken"
        ],
        correct: 0,
        explanation: "Historical Bias: Die KI wurde mit historischen Daten trainiert, als Frauen (besonders Ã¤ltere) seltener eingestellt wurden. Sie reproduziert vergangene Diskriminierung. LÃ¶sung: Diversere Trainingsdaten, Fairness-Tests, regelmÃ¤ÃŸige Audits. Genau wie bei Amazon passiert - die mussten ihr System einstampfen!",
        tip: "ðŸ•°ï¸ Vergangenheit prÃ¤gt KI - aber muss nicht die Zukunft bestimmen."
      },
      {
        question: "Eine Gesundheits-KI diagnostiziert Hautkrebs. Bei dunkler Haut ist die Fehlerrate 3x hÃ¶her. Welcher Bias ist das?",
        options: [
          "Representation Bias",
          "Confirmation Bias",
          "Aggregation Bias",
          "Population Bias"
        ],
        correct: 0,
        explanation: "Representation Bias: Die Trainingsdaten enthielten hauptsÃ¤chlich Bilder heller Haut. Dunkle HauttÃ¶ne waren unterreprÃ¤sentiert. Ergebnis: LebensgefÃ¤hrliche Fehldiagnosen bei People of Color. Echtes Problem in der Medizin! LÃ¶sung: Diverse, reprÃ¤sentative DatensÃ¤tze sammeln.",
        tip: "ðŸ‘¥ Trainingsdaten mÃ¼ssen die echte Vielfalt widerspiegeln."
      },
      {
        question: "Ihr testet eine Recruiting-KI nur mit IT-Bewerbungen, nutzt sie dann fÃ¼r alle Bereiche. Was ist das Hauptproblem?",
        options: [
          "Kein Problem - KI ist universell",
          "Evaluation Bias - falsche Testdaten",
          "Deployment Bias - falsche Einsatzumgebung",
          "Beide: Evaluation UND Deployment Bias"
        ],
        correct: 3,
        explanation: "Doppeltes Problem! Evaluation Bias: Tests mit unpassenden Daten (nur IT). Deployment Bias: Einsatz in falschem Kontext (alle Abteilungen). Eine IT-Recruiting-KI weiÃŸ nichts Ã¼ber gute PflegekrÃ¤fte oder Handwerker. Sie wird versagen und diskriminieren. Jedes System braucht passende Tests UND passenden Einsatz!",
        tip: "ðŸŽ¯ Der Kontext zÃ¤hlt: Nicht jede KI passt Ã¼berall."
      },
      {
        question: "Eure Kredit-KI lehnt systematisch Menschen aus bestimmten Stadtteilen ab. Wie ist das rechtlich einzuordnen?",
        options: [
          "Legal, solange es statistisch begrÃ¼ndbar ist",
          "Diskriminierung - verstÃ¶ÃŸt gegen Gleichbehandlung",
          "Nur problematisch bei geschÃ¼tzten Merkmalen",
          "In Ordnung, wenn transparent kommuniziert"
        ],
        correct: 1,
        explanation: "Klare Diskriminierung! Auch wenn 'Stadtteil' kein geschÃ¼tztes Merkmal ist, ist es oft ein Proxy fÃ¼r Herkunft/Einkommen. Das verstÃ¶ÃŸt gegen GleichbehandlungsgrundsÃ¤tze UND den AI Act. Ihr haftet als Betreiber! Moderne Fairness-Tests mÃ¼ssen auch solche indirekten Diskriminierungen aufdecken.",
        tip: "âš–ï¸ Indirekte Diskriminierung ist genauso verboten wie direkte."
      },
      {
        question: "Ein Ãœbersetzungs-Tool macht aus 'The doctor' â†’ 'Der Arzt' und aus 'The nurse' â†’ 'Die Krankenschwester'. Was zeigt das?",
        options: [
          "Korrekte Statistik - ist doch meistens so",
          "Gender Bias - Stereotypen werden verstÃ¤rkt",
          "Kein Problem - nur Sprache",
          "Cultural Bias"
        ],
        correct: 1,
        explanation: "Gender Bias: Die KI reproduziert Geschlechterstereotypen aus den Trainingsdaten. 'Doctor' wird mÃ¤nnlich, 'Nurse' weiblich - unabhÃ¤ngig vom Kontext. Das verfestigt Vorurteile und kann reale Auswirkungen haben (z.B. bei Stellenanzeigen). Moderne KI sollte Kontext nutzen oder neutral bleiben.",
        tip: "ðŸ‘¨â€âš•ï¸ðŸ‘©â€âš•ï¸ Berufe haben kein Geschlecht - KI sollte das auch wissen."
      },
      {
        question: "Eure Gesichtserkennungs-KI fÃ¼r den Zutritt funktioniert bei Frauen schlechter. Was ist die beste erste MaÃŸnahme?",
        options: [
          "Schwellenwert herabsetzen (akzeptiert mehr Fehler)",
          "Trainingsdaten auf Geschlechterverteilung prÃ¼fen",
          "Nur fÃ¼r MÃ¤nner einsetzen",
          "System ist fehlerhaft - Anbieter kontaktieren"
        ],
        correct: 1,
        explanation: "Erst verstehen, dann handeln! Wahrscheinlich Representation Bias in den Trainingsdaten (zu wenig Frauengesichter). PrÃ¼fen: Datenverteilung, Fehlerraten pro Gruppe, Testszenarien. Dann: Nachfordern diverserer Daten vom Anbieter ODER System nicht einsetzen. Schwellenwert senken versteckt nur das Problem!",
        tip: "ðŸ” Problem verstehen kommt vor schneller LÃ¶sung."
      },
      {
        question: "KI fÃ¼r Sozialleistungen empfiehlt seltener Weiterbildungen fÃ¼r Ã„ltere. Was ist die richtige Reaktion?",
        options: [
          "Akzeptieren - statistisch begrÃ¼ndet",
          "Sofort stoppen und Ã¼berprÃ¼fen lassen",
          "Diskret korrigieren, nicht kommunizieren",
          "Nur nutzen, wenn Mitarbeiter final entscheiden"
        ],
        correct: 1,
        explanation: "Altersdiskriminierung! Sofort Pause und externe PrÃ¼fung. Das ist Hochrisiko-KI + potenzielle Grundrechtsverletzung. Ihr braucht: Bias-Audit, Fairness-Tests, evtl. Nachschulung des Modells. 'Menschliche Aufsicht' allein reicht nicht - wenn Menschen der KI blind vertrauen (Automation Bias), wird trotzdem diskriminiert. Transparenz ist Pflicht!",
        tip: "ðŸ›‘ Bei Diskriminierungsrisiko: Stopp vor Analyse."
      },
      {
        question: "Welches Szenario ist KEIN Hochrisiko nach EU AI Act?",
        options: [
          "KI bewertet Lehramts-PrÃ¼fungen",
          "KI sortiert Eingangsrechnungen nach PrioritÃ¤t",
          "KI entscheidet Ã¼ber Wohnungszuteilung",
          "KI analysiert Mitarbeiter-Leistung"
        ],
        correct: 1,
        explanation: "Rechnungs-Priorisierung = geringes/minimales Risiko! Die anderen drei sind Hochrisiko: Bildung (PrÃ¼fungen), Zugang zu Grundleistungen (Wohnung), HR (Mitarbeiter-Bewertung). Diese beeinflussen Lebenschancen und Grundrechte massiv. Rechnungen sortieren? Keine Auswirkung auf Menschen. Kontext ist alles!",
        tip: "ðŸ“Š Hochrisiko = Auswirkung auf Grundrechte oder Lebenschancen."
      },
      {
        question: "Predictive-Policing-KI sagt fÃ¼r bestimmte Bezirke hÃ¶here KriminalitÃ¤t voraus. Was ist kritisch zu bedenken?",
        options: [
          "Zeigt nur Fakten - Daten lÃ¼gen nicht",
          "KÃ¶nnte Self-Fulfilling Prophecy sein (mehr Polizei â†’ mehr Funde)",
          "Ist verboten - sofort abschalten",
          "Legal, aber ethisch fragwÃ¼rdig"
        ],
        correct: 1,
        explanation: "Feedback Loop Problem! Mehr Polizei in einem Bezirk â†’ mehr Kontrollen â†’ mehr registrierte Delikte â†’ KI sagt 'mehr KriminalitÃ¤t' voraus â†’ noch mehr Polizei. Das ist ein sich selbst verstÃ¤rkender Kreislauf, kein objektives Bild. Plus: Oft steckt Historical Bias drin (vergangene diskriminierende Polizeiarbeit). Predictive Policing ist hochumstritten!",
        tip: "ðŸ”„ KI kann Probleme nicht nur zeigen, sondern auch verstÃ¤rken."
      },
      {
        question: "Was gehÃ¶rt zur 'menschlichen Aufsicht' bei Hochrisiko-KI im Kern?",
        options: [
          "Ein Mensch muss das System bedienen",
          "RegelmÃ¤ÃŸige Updates einspielen",
          "Verstehen, eingreifen und Ã¼berstimmen kÃ¶nnen",
          "Monatliche Berichte lesen"
        ],
        correct: 2,
        explanation: "Echte Aufsicht bedeutet: System verstehen, Ergebnisse kritisch prÃ¼fen kÃ¶nnen, bei Problemen eingreifen, KI-Entscheidung Ã¼berstimmen kÃ¶nnen. Nur 'durchwinken' reicht nicht - das ist Automation Bias! Menschen mÃ¼ssen geschult sein und die Kompetenz haben, die KI zu hinterfragen.",
        tip: "ðŸ‘¤ Menschliche Aufsicht = kompetent hinterfragen kÃ¶nnen."
      }
    ],
    3: [
      {
        question: "Eure Bewerbungs-KI benachteiligt Frauen UND Ã„ltere gleichzeitig stÃ¤rker als einzeln. Wie nennt man dieses PhÃ¤nomen?",
        options: [
          "Doppel-Bias",
          "Intersektionaler Bias",
          "Aggregation Bias",
          "Compounding Bias"
        ],
        correct: 1,
        explanation: "Intersektionaler Bias: Mehrere Diskriminierungsdimensionen verstÃ¤rken sich gegenseitig. Ã„ltere Frauen werden STÃ„RKER benachteiligt als die Summe von 'Ã¤lter' + 'weiblich'. Real bei Amazon passiert. LÃ¶sung: Fairness-Tests mÃ¼ssen intersektionale Gruppen separat analysieren, nicht nur einzelne Merkmale. Extrem wichtig, wird oft Ã¼bersehen!",
        tip: "ðŸ”€ Diskriminierung addiert sich nicht - sie multipliziert sich."
      },
      {
        question: "Wann ist eine Grundrechte-FolgenabschÃ¤tzung verpflichtend?",
        options: [
          "Bei jeder KI-Nutzung",
          "Bei Hochrisiko-KI, die Grundrechte berÃ¼hrt",
          "Nur bei biometrischer Erkennung",
          "Nur fÃ¼r BehÃ¶rden, nicht fÃ¼r Unternehmen"
        ],
        correct: 1,
        explanation: "Hochrisiko-KI mit Grundrechtsbezug braucht Impact Assessment: Welche Grundrechte betroffen? Wie stark? Welche SchutzmaÃŸnahmen? Beispiele: HR-Systeme (Gleichbehandlung), Social Scoring (MenschenwÃ¼rde), Gesundheits-KI (Diskriminierungsschutz). Gilt fÃ¼r BehÃ¶rden UND Unternehmen. Dokumentationspflicht!",
        tip: "ðŸ“‹ Impact Assessments sind eure Versicherung bei Problemen."
      },
      {
        question: "Ihr seid 'Betreiber', der Anbieter liefert ein Update. Nach Problemen: Wer haftet primÃ¤r?",
        options: [
          "Nur der Anbieter",
          "Nur ihr als Betreiber",
          "Beide - je nach Art des Problems",
          "Niemand - Updates sind Kulanz"
        ],
        correct: 2,
        explanation: "Geteilte Haftung! Anbieter haftet fÃ¼r: Systemfehler, falsche Dokumentation, nicht gemeldete Risiken. Betreiber haftet fÃ¼r: Falsche Nutzung, fehlende Aufsicht, ignorierte Warnungen. Nach Update: Ihr mÃ¼sst prÃ¼fen, ob System noch zweckgemÃ¤ÃŸ funktioniert. Blind installieren = volles Risiko bei euch!",
        tip: "âš–ï¸ Haftung teilen = Verantwortung teilen = Kommunikation wichtig."
      },
      {
        question: "KI lehnt Kredit ab mit BegrÃ¼ndung: 'Algorithmus-Score zu niedrig'. Ist das rechtlich ausreichend?",
        options: [
          "Ja - GeschÃ¤ftsgeheimnis geschÃ¼tzt",
          "Nein - konkrete, verstÃ¤ndliche GrÃ¼nde nÃ¶tig",
          "Kommt auf den Kreditbetrag an",
          "Ja, wenn DatenschutzerklÃ¤rung verlinkt ist"
        ],
        correct: 1,
        explanation: "'Score zu niedrig' ist KEINE ausreichende BegrÃ¼ndung! Betroffene haben Recht auf verstÃ¤ndliche ErklÃ¤rung: Welche Faktoren? Warum abgelehnt? Wie verbessern? Das gilt auch, wenn der Algorithmus komplex ist. 'Explainable AI' ist keine KÃ¼r, sondern Pflicht bei Hochrisiko-Entscheidungen. GeschÃ¤ftsgeheimnisse schÃ¼tzen nicht vor Transparenzpflicht!",
        tip: "ðŸ’¬ 'Black Box' ist keine Ausrede - ErklÃ¤rungen sind Pflicht."
      },
      {
        question: "Sachbearbeiter folgen KI-Empfehlungen zu 95%. Was ist die beste GegenmaÃŸnahme fÃ¼r Automation Bias?",
        options: [
          "Ist gut - zeigt Vertrauen in das System",
          "Random Audits + Schulung zu kritischem Hinterfragen",
          "KI-Konfidenz-Level niedriger anzeigen",
          "Mehr FÃ¤lle pro Tag zur besseren Auslastung"
        ],
        correct: 1,
        explanation: "95% Zustimmung ist Warnsignal fÃ¼r Automation Bias - Menschen vertrauen der KI blind! GegenmaÃŸnahmen: RegelmÃ¤ÃŸige Stichproben wo Menschen aktiv hinterfragen mussten, Schulungen zu Bias-Erkennung, FÃ¤lle zeigen wo KI falsch lag, Kultur des kritischen Denkens fÃ¶rdern. NICHT: Mehr Zeitdruck (verstÃ¤rkt Bias)!",
        tip: "ðŸ¤– Zu viel Vertrauen in KI ist genauso gefÃ¤hrlich wie zu wenig."
      },
      {
        question: "Wer muss die technische Dokumentation bei zugekaufter Hochrisiko-KI erstellen?",
        options: [
          "Anbieter erstellt, Betreiber nutzt sie",
          "Betreiber erstellt alles selbst",
          "Beide erstellen separate Dokumentationen",
          "Nur bei selbst entwickelter KI nÃ¶tig"
        ],
        correct: 0,
        explanation: "Anbieter muss technische Dokumentation liefern (wie trainiert? Welche Daten? Risiken? Testresultate?). Betreiber muss sie NUTZEN: Verstehen, umsetzen, ggf. ergÃ¤nzen (Einsatzkontext, AufsichtsmaÃŸnahmen). Bei zugekaufter KI: Dokumentation einfordern! Ist sie mangelhaft/fehlt â†’ System nicht einsetzen oder nur auf eigenes Risiko.",
        tip: "ðŸ“š Dokumentation ist eure Gebrauchsanweisung - ohne geht's nicht."
      },
      {
        question: "Eure HR-KI hat 3 Monate lang diskriminiert. Besteht eine Meldepflicht?",
        options: [
          "Nein - interne Angelegenheit",
          "Nur wenn Betroffene sich beschweren",
          "Ja - an zustÃ¤ndige AufsichtsbehÃ¶rde",
          "Nur wenn Ã¼ber 100 Personen betroffen"
        ],
        correct: 2,
        explanation: "Schwere VorfÃ¤lle MÃœSSEN gemeldet werden - an nationale AufsichtsbehÃ¶rde (in DE: Bundesnetzagentur). 'Schwer' = Grundrechte verletzt, systemischer Fehler, erhebliche Anzahl Betroffener. Nicht melden = zusÃ¤tzliche Strafe! Proaktiv melden zeigt Verantwortung, kann Strafen mildern. Verstecken macht alles schlimmer.",
        tip: "ðŸ“ž Transparenz bei Problemen ist Pflicht, nicht optional."
      },
      {
        question: "Was ist der Hauptvorteil einer KI-Sandbox fÃ¼r KMUs?",
        options: [
          "KI darf ohne EinschrÃ¤nkungen getestet werden",
          "Keine Strafen bei VerstÃ¶ÃŸen wÃ¤hrend des Tests",
          "Kostenlose KI-Entwicklung durch BehÃ¶rden",
          "Automatische Zertifizierung nach Testphase"
        ],
        correct: 1,
        explanation: "Sandboxes = geschÃ¼tzter Testrahmen unter BehÃ¶rdenaufsicht. KMUs kÃ¶nnen innovative KI testen OHNE Strafen zu riskieren, wenn sie sich an den Plan halten und kooperieren. ABER: Keine Haftungsbefreiung fÃ¼r SchÃ¤den an Dritten! Auch kein Freifahrtschein - Tests mÃ¼ssen sinnvoll sein. Gibt's in DE bei der Bundesnetzagentur.",
        tip: "ðŸ–ï¸ Sandbox = sicher experimentieren, nicht Freibrief zum Chaos."
      },
      {
        question: "Bei KI-Einkauf sagt der Anbieter: 'Bias-Tests sind zu komplex fÃ¼r uns.' Wie bewerten Sie das?",
        options: [
          "Akzeptabel - sind wirklich komplex",
          "K.O.-Kriterium bei Hochrisiko-KI",
          "Nur bei groÃŸen Anbietern erwartbar",
          "Kann intern nachgeholt werden"
        ],
        correct: 1,
        explanation: "Red Flag! Wenn ein Anbieter keine Bias-Tests macht/kann, ist das bei Hochrisiko-KI ein K.O.-Kriterium. Ihr haftet mit, wenn ihr es trotzdem einsetzt. Auch problematisch: 'StÃ¤ndiges Training' ohne Kontrolle (Drift-Risiko), 'keine Transparenz' (verstÃ¶ÃŸt gegen AI Act). Fordert konkrete Nachweise: Test-Reports, Fehlerraten pro Gruppe, AuditierungsmÃ¶glichkeiten.",
        tip: "ðŸš© Bei Hochrisiko-KI gibt es keinen Rabatt auf Sicherheit."
      },
      {
        question: "Was ist langfristig der wichtigste Erfolgsfaktor fÃ¼r verantwortungsvolle KI-Nutzung?",
        options: [
          "Teuerste und modernste KI kaufen",
          "Kontinuierliche Schulung + kritische PrÃ¼fkultur etablieren",
          "Alle Entscheidungen dokumentieren",
          "Externe Berater fÃ¼r jede Entscheidung"
        ],
        correct: 1,
        explanation: "Die beste KI hilft nichts ohne kompetente Menschen! Kontinuierliche Schulung (KI entwickelt sich weiter), kritische Grundhaltung (Automation Bias vermeiden), interdisziplinÃ¤re Teams (Tech + Ethik + Recht + Fachbereich). Dokumentation ist wichtig, aber ohne VerstÃ¤ndnis wertlos. Kein Tool ersetzt menschliches UrteilsvermÃ¶gen - das ist die Kernaussage des AI Act!",
        tip: "ðŸŽ¯ Menschen bleiben der wichtigste Faktor - heute und morgen."
      }
    ]
  };

  const learningContent = {
    euAiAct: {
      title: "EU AI Act Grundlagen",
      sections: [
        {
          title: "Die 4 Risikoklassen",
          content: [
            { risk: "Unannehmbares Risiko", color: "text-rose-400", desc: "Komplett verboten (z.B. Social Scoring, Manipulation)" },
            { risk: "Hochrisiko", color: "text-orange-400", desc: "Strenge Auflagen (z.B. HR, Kreditvergabe, Gesundheit)" },
            { risk: "Begrenztes Risiko", color: "text-amber-400", desc: "Transparenzpflicht (z.B. Chatbots, generative KI)" },
            { risk: "Minimales Risiko", color: "text-emerald-400", desc: "Kaum Pflichten (z.B. Spam-Filter, Empfehlungssysteme)" }
          ]
        },
        {
          title: "Wichtige Fristen",
          content: [
            { date: "Februar 2025", desc: "Verbotene KI-Systeme mÃ¼ssen eingestellt werden" },
            { date: "Februar 2025", desc: "Schulungspflicht fÃ¼r Mitarbeiter (mit Dokumentation)" },
            { date: "August 2025", desc: "Pflichten fÃ¼r General Purpose AI (GPAI) Anbieter" },
            { date: "August 2026", desc: "Volle Umsetzung aller Hochrisiko-Anforderungen" }
          ]
        }
      ]
    },
    biasTypes: {
      title: "KI-Bias verstehen",
      sections: [
        {
          title: "Die wichtigsten Bias-Typen",
          content: [
            { type: "Historical Bias", desc: "KI reproduziert vergangene Diskriminierung aus Trainingsdaten", example: "Amazon Recruiting-KI bevorzugte MÃ¤nner" },
            { type: "Representation Bias", desc: "Bestimmte Gruppen sind in Trainingsdaten unterreprÃ¤sentiert", example: "Hautkrebs-KI versagt bei dunkler Haut" },
            { type: "Evaluation Bias", desc: "Getestet wird mit falschen/unpassenden Daten", example: "IT-Recruiting-KI nicht fÃ¼r Pflege getestet" },
            { type: "Deployment Bias", desc: "System wird in falschem Kontext eingesetzt", example: "KI fÃ¼r Kontext A in Kontext B genutzt" },
            { type: "Automation Bias", desc: "Menschen vertrauen KI blind und hinterfragen nicht", example: "95% der KI-VorschlÃ¤ge werden Ã¼bernommen" },
            { type: "Intersektionaler Bias", desc: "Mehrere Diskriminierungen verstÃ¤rken sich gegenseitig", example: "Ã„ltere Frauen doppelt benachteiligt" }
          ]
        }
      ]
    },
    responsibilities: {
      title: "Rollen & Verantwortung",
      sections: [
        {
          title: "Anbieter vs. Betreiber",
          content: [
            { role: "Anbieter", duties: "Entwickelt/liefert das System, erstellt technische Dokumentation, fÃ¼hrt Risikotests durch, meldet schwere VorfÃ¤lle" },
            { role: "Betreiber", duties: "Nutzt das System, stellt menschliche Aufsicht sicher, dokumentiert Schulungen, meldet Probleme" },
            { role: "Beide", duties: "Tragen gemeinsam Verantwortung fÃ¼r sichere und faire KI-Nutzung" }
          ]
        }
      ]
    },
    resources: {
      title: "WeiterfÃ¼hrende Links",
      links: [
        { title: "Offizieller EU AI Act Text", url: "https://artificialintelligenceact.eu/de/", desc: "VollstÃ¤ndiger Gesetzestext und Updates" },
        { title: "Bundesnetzagentur - KI Service-Desk", url: "https://www.bundesnetzagentur.de/", desc: "Deutsche AufsichtsbehÃ¶rde mit Tools und Beratung" },
        { title: "EU Kommission - AI Office", url: "https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai", desc: "Zentrale Anlaufstelle fÃ¼r KI-Fragen" },
        { title: "KMU-Leitfaden zum AI Act", url: "https://artificialintelligenceact.eu/de/small-businesses-guide-to-the-ai-act/", desc: "Speziell fÃ¼r kleine und mittlere Unternehmen" },
        { title: "Bias in AI - Ressourcen", url: "https://www.ibm.com/de-de/think/topics/ai-bias", desc: "Vertiefende Informationen zu KI-Verzerrungen" }
      ]
    }
  };

  const levelInfo = {
    1: {
      title: "Level 1: Grundlagen",
      icon: Brain,
      gradient: "from-emerald-500 to-teal-600",
      bg: "bg-emerald-500",
      description: "Basics des EU AI Act und erste Schritte"
    },
    2: {
      title: "Level 2: Praxis",
      icon: Zap,
      gradient: "from-amber-500 to-orange-600",
      bg: "bg-amber-500",
      description: "Bias erkennen und Tools richtig einordnen"
    },
    3: {
      title: "Level 3: Expertise",
      icon: Target,
      gradient: "from-rose-500 to-pink-600",
      bg: "bg-rose-500",
      description: "Compliance und komplexe Szenarien meistern"
    }
  };

  const handleAnswer = (answerIndex) => {
    if (showExplanation) return;

    setSelectedAnswer(answerIndex);
    setShowExplanation(true);

    const isCorrect = answerIndex === questions[currentLevel][currentQuestion].correct;
    const newScores = [...levelScores[currentLevel], isCorrect];
    setLevelScores({ ...levelScores, [currentLevel]: newScores });
  };

  const handleNext = () => {
    if (currentQuestion < questions[currentLevel].length - 1) {
      setCurrentQuestion(currentQuestion + 1);
      setSelectedAnswer(null);
      setShowExplanation(false);
    } else {
      const score = levelScores[currentLevel].filter(s => s).length;
      const total = questions[currentLevel].length;
      const percentage = (score / total) * 100;

      if (percentage >= 70 && !completedLevels.includes(currentLevel)) {
        setCompletedLevels([...completedLevels, currentLevel]);
      }

      setView('levelComplete');
    }
  };

  const startLevel = (level) => {
    setCurrentLevel(level);
    setCurrentQuestion(0);
    setSelectedAnswer(null);
    setShowExplanation(false);
    setView('question');
  };

  const restartLevel = () => {
    setLevelScores({ ...levelScores, [currentLevel]: [] });
    startLevel(currentLevel);
  };

  const goToMenu = () => {
    setView('menu');
    setCurrentQuestion(0);
    setSelectedAnswer(null);
    setShowExplanation(false);
  };

  const isLevelUnlocked = (level) => {
    if (level === 1) return true;
    return completedLevels.includes(level - 1);
  };

  const getLevelScore = (level) => {
    const scores = levelScores[level];
    if (scores.length === 0) return null;
    const correct = scores.filter(s => s).length;
    return { correct, total: scores.length, percentage: Math.round((correct / scores.length) * 100) };
  };

  // Learning Area View
  if (view === 'learn') {
    return (
      <div className="min-h-screen bg-[var(--pa-bg)] p-6">
        <div className="max-w-5xl mx-auto">
          <div className="mb-6 flex items-center justify-between">
            <div className="flex items-center gap-3">
              <button
                onClick={goToMenu}
                className="p-2 hover:bg-slate-700 rounded-lg transition"
              >
                <Home className="w-6 h-6 text-slate-300" />
              </button>
              <h1 className="text-3xl font-bold text-white">Wissensbereich</h1>
            </div>
          </div>

          {/* EU AI Act */}
          <div className="bg-slate-800 rounded-2xl shadow-2xl p-8 mb-6 border border-slate-700">
            <h2 className="text-2xl font-bold text-emerald-400 mb-6 flex items-center gap-3">
              <Brain className="w-8 h-8" />
              {learningContent.euAiAct.title}
            </h2>

            {learningContent.euAiAct.sections.map((section, idx) => (
              <div key={idx} className="mb-6 last:mb-0">
                <h3 className="text-xl font-bold text-white mb-4">{section.title}</h3>
                <div className="space-y-3">
                  {section.content.map((item, i) => (
                    <div key={i} className="bg-slate-700/50 rounded-lg p-4">
                      {item.risk ? (
                        <>
                          <div className={`font-bold mb-1 ${item.color}`}>{item.risk}</div>
                          <div className="text-slate-300 text-sm">{item.desc}</div>
                        </>
                      ) : (
                        <>
                          <div className="font-bold text-amber-400 mb-1">{item.date}</div>
                          <div className="text-slate-300 text-sm">{item.desc}</div>
                        </>
                      )}
                    </div>
                  ))}
                </div>
              </div>
            ))}
          </div>

          {/* Bias Types */}
          <div className="bg-slate-800 rounded-2xl shadow-2xl p-8 mb-6 border border-slate-700">
            <h2 className="text-2xl font-bold text-amber-400 mb-6 flex items-center gap-3">
              <AlertCircle className="w-8 h-8" />
              {learningContent.biasTypes.title}
            </h2>

            <div className="space-y-4">
              {learningContent.biasTypes.sections[0].content.map((item, i) => (
                <div key={i} className="bg-slate-700/50 rounded-lg p-5">
                  <div className="font-bold text-amber-300 mb-2">{item.type}</div>
                  <div className="text-slate-300 mb-2">{item.desc}</div>
                  <div className="text-slate-400 text-sm italic">Beispiel: {item.example}</div>
                </div>
              ))}
            </div>
          </div>

          {/* Responsibilities */}
          <div className="bg-slate-800 rounded-2xl shadow-2xl p-8 mb-6 border border-slate-700">
            <h2 className="text-2xl font-bold text-rose-400 mb-6 flex items-center gap-3">
              <Target className="w-8 h-8" />
              {learningContent.responsibilities.title}
            </h2>

            <div className="space-y-4">
              {learningContent.responsibilities.sections[0].content.map((item, i) => (
                <div key={i} className="bg-slate-700/50 rounded-lg p-5">
                  <div className="font-bold text-rose-300 mb-2">{item.role}</div>
                  <div className="text-slate-300">{item.duties}</div>
                </div>
              ))}
            </div>
          </div>

          {/* Resources */}
          <div className="bg-slate-800 rounded-2xl shadow-2xl p-8 border border-slate-700">
            <h2 className="text-2xl font-bold text-blue-400 mb-6 flex items-center gap-3">
              <BookOpen className="w-8 h-8" />
              {learningContent.resources.title}
            </h2>

            <div className="space-y-3">
              {learningContent.resources.links.map((link, i) => (
                <a
                  key={i}
                  href={link.url}
                  target="_blank"
                  rel="noopener noreferrer"
                  className="block bg-slate-700/50 rounded-lg p-5 hover:bg-slate-700 transition group"
                >
                  <div className="flex items-start justify-between gap-3">
                    <div>
                      <div className="font-bold text-blue-300 mb-1 group-hover:text-blue-200 flex items-center gap-2">
                        {link.title}
                        <ExternalLink className="w-4 h-4" />
                      </div>
                      <div className="text-slate-400 text-sm">{link.desc}</div>
                    </div>
                  </div>
                </a>
              ))}
            </div>
          </div>
        </div>
      </div>
    );
  }

  // Level Complete View
  if (view === 'levelComplete') {
    const levelScore = getLevelScore(currentLevel);
    const passed = levelScore && levelScore.percentage >= 70;

    return (
      <div className="min-h-screen bg-[var(--pa-bg)] p-6">
        <div className="max-w-2xl mx-auto">
          <div className="bg-white rounded-2xl shadow-2xl p-8 text-center">
            {passed ? (
              <Trophy className="w-24 h-24 text-amber-500 mx-auto mb-6 animate-bounce" />
            ) : (
              <Award className="w-24 h-24 text-slate-400 mx-auto mb-6" />
            )}

            <h2 className="text-4xl font-bold mb-3 text-slate-800">
              {passed ? "Level geschafft! ðŸŽ‰" : "Noch nicht ganz..."}
            </h2>

            <div
              className="text-7xl font-bold mb-6"
              style={{ color: passed ? '#10b981' : '#f59e0b' }}
            >
              {levelScore.percentage}%
            </div>

            <p className="text-xl text-slate-600 mb-8">
              {levelScore.correct} von {levelScore.total} Fragen richtig
            </p>

            {passed ? (
              <div className="bg-emerald-50 border-2 border-emerald-300 rounded-xl p-5 mb-8">
                <p className="text-emerald-900 font-medium text-lg">
                  Starke Leistung! Du hast ein solides VerstÃ¤ndnis bewiesen.
                  {currentLevel < 3 && " Das nÃ¤chste Level ist jetzt freigeschaltet!"}
                </p>
              </div>
            ) : (
              <div className="bg-amber-50 border-2 border-amber-300 rounded-xl p-5 mb-8">
                <p className="text-amber-900 font-medium text-lg">
                  FÃ¼r 70% fehlt noch ein bisschen. Schau dir den Wissensbereich an oder versuchâ€™s nochmal!
                </p>
              </div>
            )}

            <div className="flex flex-wrap gap-4 justify-center">
              <button
                onClick={restartLevel}
                className="px-8 py-4 bg-slate-700 text-white rounded-xl hover:bg-slate-800 transition font-semibold shadow-lg"
              >
                Level wiederholen
              </button>

              {passed && currentLevel < 3 && isLevelUnlocked(currentLevel + 1) && (
                <button
                  onClick={() => startLevel(currentLevel + 1)}
                  className="pa-btn pa-btn-primary"
                >
                  NÃ¤chstes Level â†’
                </button>
              )}

              <button
                onClick={goToMenu}
                className="pa-btn pa-btn-secondary"
              >
                Zur Ãœbersicht
              </button>
            </div>
          </div>
        </div>
      </div>
    );
  }

  // Menu View
  if (view === 'menu') {
    return (
      <div className="min-h-screen bg-[var(--pa-bg)] p-6">
        <div className="max-w-4xl mx-auto">
          <div className="text-center mb-10">
            <p className="text-xs tracking-[0.25em] uppercase text-slate-400 mb-3">
              Lernen
            </p>
            <h1 className="text-5xl font-bold mb-3 text-[var(--pa-foreground)]">
              KI-Kompetenztest&nbsp;
              <span className="text-[var(--accent-cyan)]">EU AI Act</span>
            </h1>
            <p className="text-slate-300 text-lg">Spielerisch lernen, sicher anwenden</p>
          </div>

          <div className="space-y-6">
            {[1, 2, 3].map(level => {
              const unlocked = isLevelUnlocked(level);
              const completed = completedLevels.includes(level);
              const score = getLevelScore(level);
              const Icon = levelInfo[level].icon;

              return (
                <div
                  key={level}
                  className={`bg-slate-800 rounded-2xl shadow-2xl p-6 border-2 transition-all ${
                    unlocked
                      ? 'border-slate-600 cursor-pointer hover:border-slate-400 hover:shadow-emerald-500/20'
                      : 'border-slate-700 opacity-60'
                  }`}
                  onClick={() => unlocked && startLevel(level)}
                >
                  <div className="flex items-center gap-5">
                    <div className="w-14 h-14 rounded-xl border border-[var(--accent-cyan)] flex items-center justify-center bg-[rgba(0,250,255,0.08)]">
                      {unlocked ? (
                        <Icon className="w-8 h-8 text-[var(--accent-cyan)]" />
                      ) : (
                        <Lock className="w-8 h-8 text-[var(--accent-cyan)]" />
                      )}
                    </div>

                    <div className="flex-1">
                      <h3 className="text-2xl font-bold mb-2 text-white">{levelInfo[level].title}</h3>
                      <p className="text-slate-300 mb-2">{levelInfo[level].description}</p>
                      <p className="text-slate-400 text-sm">
                        {questions[level].length} Fragen
                      </p>
                    </div>

                    <div className="text-right min-w-[120px]">
                      {completed && (
                        <div className="flex items-center gap-2 text-emerald-400 mb-2 justify-end">
                          <CheckCircle className="w-6 h-6" />
                          <span className="font-semibold text-lg">Geschafft!</span>
                        </div>
                      )}
                      {score && (
                        <div className="text-3xl font-bold" style={{
                          color: score.percentage >= 70 ? '#10b981' : '#f59e0b'
                        }}>
                          {score.percentage}%
                        </div>
                      )}
                      {!unlocked && (
                        <div className="text-slate-500 text-sm">
                          Vorheriges Level abschlieÃŸen
                        </div>
                      )}
                    </div>
                  </div>
                </div>
              );
            })}
          </div>

          <div className="mt-6 pa-card">
            <button
              type="button"
              onClick={() => setShowHowItWorks((v) => !v)}
              className="flex w-full items-center justify-between text-left"
            >
              <span className="flex items-center gap-2 font-semibold text-[var(--accent-cyan)]">
                <Zap className="w-4 h-4" />
                So funktioniertâ€™s
              </span>
              <span className="text-slate-400 text-sm">
                {showHowItWorks ? "Details ausblenden" : "Details anzeigen"}
              </span>
            </button>
            {showHowItWorks && (
              <ul className="mt-4 text-slate-300 space-y-3">
                <li className="flex items-start gap-3">
                  <span className="text-emerald-400 text-xl">âœ“</span>
                  <span>Single-Choice Fragen â€“ nur EINE Antwort ist korrekt</span>
                </li>
                <li className="flex items-start gap-3">
                  <span className="text-emerald-400 text-xl">âœ“</span>
                  <span>Sofortige, verstÃ¤ndliche ErklÃ¤rungen nach jeder Antwort</span>
                </li>
                <li className="flex items-start gap-3">
                  <span className="text-emerald-400 text-xl">âœ“</span>
                  <span>Mindestens 70% richtig â†’ nÃ¤chstes Level freischalten</span>
                </li>
                <li className="flex items-start gap-3">
                  <span className="text-emerald-400 text-xl">âœ“</span>
                  <span>Wissensbereich mit allen Infos zum Nachschlagen</span>
                </li>
              </ul>
            )}
          </div>
        </div>
      </div>
    );
  }

  // Question View
  const currentQ = questions[currentLevel][currentQuestion];
  const LevelIcon = levelInfo[currentLevel].icon;

  return (
    <div className="min-h-screen bg-[var(--pa-bg)] p-6">
        <div className="max-w-3xl mx-auto">
          {/* Header */}
          <div className="mb-6 flex items-center justify-between bg-slate-800 rounded-xl p-4 shadow-lg">
            <div className="flex items-center gap-3">
            <button
              onClick={goToMenu}
              className="p-2 hover:bg-slate-700 rounded-lg transition"
              title="ZurÃ¼ck zur Ãœbersicht"
              >
                <Home className="w-5 h-5 text-slate-300" />
              </button>
            <div className="w-10 h-10 rounded-lg border border-[var(--accent-cyan)] flex items-center justify-center bg-[rgba(0,250,255,0.08)]">
              <LevelIcon className="w-6 h-6 text-[var(--accent-cyan)]" />
            </div>
            <div>
              <h2 className="font-bold text-lg text-white">{levelInfo[currentLevel].title}</h2>
              <p className="text-sm text-slate-400">
                Frage {currentQuestion + 1} von {questions[currentLevel].length}
              </p>
            </div>
          </div>

          <div className="text-right">
            <div className="text-sm text-slate-400">Richtig</div>
            <div className="font-bold text-2xl text-emerald-400">
              {levelScores[currentLevel].filter(s => s).length}
            </div>
          </div>
        </div>

        {/* Progress bar */}
        <div className="mb-6 bg-slate-800 rounded-full h-3 shadow-inner">
          <div
            className="bg-[var(--accent-cyan)] h-3 rounded-full transition-all shadow-lg"
            style={{ width: `${((currentQuestion + 1) / questions[currentLevel].length) * 100}%` }}
          />
        </div>

        {/* Question card */}
        <div className="bg-slate-800 rounded-2xl shadow-2xl p-8 border border-slate-700">
          <div className="bg-blue-900/20 border border-blue-500/30 rounded-lg p-3 mb-6 flex items-center gap-2">
            <AlertCircle className="w-5 h-5 text-blue-400 flex-shrink-0" />
            <span className="text-blue-200 text-sm font-medium">WÃ¤hle die BESTE Antwort (nur eine ist korrekt)</span>
          </div>

          <h3 className="text-2xl font-bold mb-8 text-white leading-relaxed">
            {currentQ.question}
          </h3>

          <div className="space-y-4 mb-6">
            {currentQ.options.map((option, index) => {
              const isSelected = selectedAnswer === index;
              const isCorrect = index === currentQ.correct;
              const showResult = showExplanation;

              let bgColor = 'bg-slate-700 hover:bg-slate-600';
              let borderColor = 'border-slate-600';
              let textColor = 'text-slate-200';

              if (showResult) {
                if (isCorrect) {
                  bgColor = 'bg-emerald-900/50';
                  borderColor = 'border-emerald-500';
                  textColor = 'text-emerald-100';
                } else if (isSelected && !isCorrect) {
                  bgColor = 'bg-rose-900/50';
                  borderColor = 'border-rose-500';
                  textColor = 'text-rose-100';
                }
              } else if (isSelected) {
                bgColor = 'bg-blue-900/50';
                borderColor = 'border-blue-500';
                textColor = 'text-blue-100';
              }

              return (
                <button
                  key={index}
                  onClick={() => handleAnswer(index)}
                  disabled={showExplanation}
                  className={`w-full text-left p-5 rounded-xl border-2 transition-all ${bgColor} ${borderColor} ${textColor} ${
                    !showExplanation ? 'cursor-pointer hover:scale-[1.02]' : 'cursor-default'
                  } shadow-lg`}
                >
                  <div className="flex items-center gap-4">
                    <div className={`w-8 h-8 rounded-full border-2 flex items-center justify-center flex-shrink-0 ${
                      showResult && isCorrect ? 'border-emerald-400 bg-emerald-500' :
                      showResult && isSelected && !isCorrect ? 'border-rose-400 bg-rose-500' :
                      isSelected ? 'border-blue-400 bg-blue-500' : 'border-slate-500'
                    }`}>
                      {showResult && isCorrect && <CheckCircle className="w-5 h-5 text-white" />}
                      {showResult && isSelected && !isCorrect && <XCircle className="w-5 h-5 text-white" />}
                    </div>
                    <span className="flex-1 text-lg">{option}</span>
                  </div>
                </button>
              );
            })}
          </div>

          {/* Explanation */}
          {showExplanation && (
            <div className="mt-8 space-y-5 animate-fadeIn">
              <div className={`p-6 rounded-xl border-2 ${
                selectedAnswer === currentQ.correct
                  ? 'bg-emerald-900/30 border-emerald-500'
                  : 'bg-amber-900/30 border-amber-500'
              }`}>
                <div className="flex items-start gap-4">
                  <div className="text-4xl">
                    {selectedAnswer === currentQ.correct ? 'âœ“' : 'â†’'}
                  </div>
                  <div>
                    <p className={`font-bold mb-3 text-xl ${
                      selectedAnswer === currentQ.correct ? 'text-emerald-300' : 'text-amber-300'
                    }`}>
                      {selectedAnswer === currentQ.correct ? 'Richtig!' : 'Nicht ganz...'}
                    </p>
                    <p className={`leading-relaxed ${
                      selectedAnswer === currentQ.correct ? 'text-emerald-100' : 'text-amber-100'
                    }`}>
                      {currentQ.explanation}
                    </p>
                  </div>
                </div>
              </div>

              <div className="bg-blue-900/30 border-2 border-blue-500 p-5 rounded-xl">
                <p className="text-blue-100 leading-relaxed">{currentQ.tip}</p>
              </div>

              <button
                onClick={handleNext}
                className={`w-full py-5 bg-gradient-to-r ${levelInfo[currentLevel].gradient} text-white rounded-xl hover:shadow-2xl transition-all font-bold text-lg shadow-lg`}
              >
                {currentQuestion < questions[currentLevel].length - 1 ? 'NÃ¤chste Frage â†’' : 'Level abschlieÃŸen'}
              </button>
            </div>
          )}
        </div>

        {/* Score indicator */}
        {levelScores[currentLevel].length > 0 && (
          <div className="mt-6 text-center bg-slate-800 rounded-lg p-4 shadow-lg">
            <div className="text-slate-300">
              Aktuell richtig: <span className="font-bold text-emerald-400">{levelScores[currentLevel].filter(s => s).length}</span> von {levelScores[currentLevel].length}
              {' '}({Math.round((levelScores[currentLevel].filter(s => s).length / levelScores[currentLevel].length) * 100)}%)
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default KIKompetenzTest;
